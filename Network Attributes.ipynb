{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import wikipedia as wiki\n",
    "import networkx as nx\n",
    "import requests\n",
    "import os\n",
    "import math\n",
    "import datetime as dt\n",
    "from collections import Counter\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lang = 'en'\n",
    "#lang = 'de'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Get nodes from network\n",
    "#Import Edgelists\n",
    "os.chdir('path')\n",
    "DF = pd.read_csv('%s_edgelist.csv'%lang)\n",
    "\n",
    "#Produce NETWORK\n",
    "NET = nx.from_pandas_edgelist(DF, create_using=nx.DiGraph())\n",
    "NET.name = \"HYPERLINK NETWORK\"\n",
    "print(nx.info(NET))\n",
    "network_df = pd.DataFrame(index=list(NET.nodes))\n",
    "network_df.index.name = 'Article'\n",
    "network_df['Article'] = network_df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zweiter Weltkrieg</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erster Weltkrieg</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kalter Krieg</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Length\n",
       "Zweiter Weltkrieg    NaN\n",
       "Erster Weltkrieg     NaN\n",
       "Kalter Krieg         NaN"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#create list of articles\n",
    "Articles = list(network_df['Article'])\n",
    "df = pd.DataFrame(index=Articles, columns=['Length'])\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define query\n",
    "def chunks(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i+n] \n",
    "            \n",
    "def query(request):\n",
    "    request['action'] = 'query'\n",
    "    request['format'] = 'json'\n",
    "    lastContinue = {}\n",
    "    while True:\n",
    "        req = request.copy()\n",
    "        req.update(lastContinue)\n",
    "        result = requests.get('https://%s.wikipedia.org/w/api.php' %lang, params=req).json()\n",
    "        if 'error' in result:\n",
    "            raise Error(result['error'])\n",
    "        if 'warnings' in result:\n",
    "            print(result['warnings'])\n",
    "        if 'query' in result:\n",
    "            yield result['query']\n",
    "        if 'continue' not in result:\n",
    "            break\n",
    "        lastContinue = result['continue']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get page id\n",
    "for i in chunks(Articles, 50):\n",
    "    for i in query({'titles':'|'.join(i), 'prop': 'info'}):\n",
    "        for j in i['pages'].values():\n",
    "            if 'pageid' in j.keys():\n",
    "                df.loc[j['title'], 'page'] = j['pageid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Age of Article\n",
    "age = {}\n",
    "for i in chunks(Articles, 1):\n",
    "    for j in query({'titles':'|'.join(i), 'prop': 'revisions', 'rvprop':'timestamp','rvlimit':'max'}):\n",
    "        for k in j['pages'].values():\n",
    "            if 'revisions' in k.keys():\n",
    "                age[k['title']] = k['revisions'][-1]\n",
    "                \n",
    "for k,v in age.items():\n",
    "    for l,w in v.items():\n",
    "        age[k] = w\n",
    "        \n",
    "for k,v in age.items():\n",
    "    age[k] = (datetime.datetime.now() - datetime.datetime.strptime(v, \"%Y-%m-%dT%H:%M:%S%z\").replace(tzinfo=None)).days/365\n",
    "    df['Age'] = df.index.to_series().map(age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "translations = {}\n",
    "\n",
    "for i in chunks(Articles, 50):\n",
    "    tparams ={}\n",
    "    tparams['titles'] = '|'.join(i)\n",
    "    tparams['prop'] = 'langlinks'\n",
    "    tparams['lllang'] = 'en' #or 'de'         \n",
    "\n",
    "    for j in list(query(tparams, lang)):\n",
    "        for k in j['pages'].values():\n",
    "            if 'langlinks' in k.keys():\n",
    "                translations[k['title']] = k['langlinks'][0]['*']\n",
    "                \n",
    "network_df['Translation'] = network_df['Article'].map(translations)\n",
    "network_df[network_df['Translation'].isna()==True][['Article', 'Translation']]\n",
    "\n",
    "network_df['Linked EN'] = network_df['Translation'].isna()==False\n",
    "print(network_df['Linked EN'].value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GET Length\n",
    "for i in chunks(Articles, 50):\n",
    "    for i in query({'titles':'|'.join(i), 'prop': 'info'}):\n",
    "        for j in i['pages'].values():\n",
    "            if 'length' in j.keys():\n",
    "                df.loc[j['title'], 'Length'] = j['length']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDITORS   \n",
    "ed_dic={}\n",
    "anon_dic={}\n",
    "\n",
    "for i in chunks(Articles, 50):\n",
    "    for j in query({'titles':'|'.join(i), 'prop': 'contributors', 'pclimit':'max'}):\n",
    "        for k in j['pages'].values():\n",
    "            if 'contributors' in k.keys():\n",
    "                if k['title'] in ed_dic.keys():\n",
    "                    ed_dic[k['title']].extend(k['contributors'])\n",
    "                else:\n",
    "                    ed_dic[k['title']] = k['contributors']\n",
    "            if 'anoncontributors' in k.keys():\n",
    "                anon_dic[k['title']] = k['anoncontributors']\n",
    "\n",
    "for k, v in ed_dic.items():\n",
    "    ed_dic[k] = len(v)\n",
    "    df['Reg-Editors'] = df.index.to_series().map(ed_dic)\n",
    "\n",
    "for k, v in anon_dic.items():\n",
    "    df['Anon-Editors'] = df.index.to_series().map(anon_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EDITS\n",
    "rev_dic = {}\n",
    "\n",
    "for i in chunks(Articles,1):\n",
    "    for j in query({'titles':'|'.join(i), 'prop': 'revisions', 'rvprop':'user|size','rvlimit':'max'}):\n",
    "            for k in j['pages'].values():\n",
    "                if 'revisions' in k.keys():\n",
    "                    if k['title'] in rev_dic.keys():\n",
    "                        rev_dic[k['title']].extend(k['revisions'])\n",
    "                    else:\n",
    "                        rev_dic[k['title']] = k['revisions']\n",
    "\n",
    "for k, v in rev_dic.items():\n",
    "    rev_dic[k] = len(v)\n",
    "    df['Edits'] = df.index.to_series().map(rev_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE NEW COLUMNS\n",
    "df = df.fillna(0)\n",
    "df['Total-Editors'] = df['Reg-Editors'] + df['Anon-Editors']\n",
    "df['Prop-Anonymous'] = df['Anon-Editors'] / df['Total-Editors']\n",
    "df['Edits/Editors'] = df['Edits'] / df['Total-Editors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrape in-text citations\n",
    "\n",
    "#Define query\n",
    "def chunks(l, n):\n",
    "        for i in range(0, len(l), n):\n",
    "            yield l[i:i+n] \n",
    "            \n",
    "#Define query\n",
    "def query(request):\n",
    "    global result\n",
    "    request['action'] = 'parse'\n",
    "    request['format'] = 'json'\n",
    "    lastContinue = {}\n",
    "    while True:\n",
    "        try:\n",
    "            req = request.copy()\n",
    "            req.update(lastContinue)\n",
    "            result = requests.get('https://%s.wikipedia.org/w/api.php'%lang, params=req).json()\n",
    "            if 'error' in result:\n",
    "                return []     \n",
    "            if 'IncompleteRead' in result:\n",
    "                return []\n",
    "            if 'warnings' in result:\n",
    "                print(result['warnings'])\n",
    "            if 'parse' in result:\n",
    "                yield result['parse']\n",
    "            if 'continue' not in result:\n",
    "                break\n",
    "            lastContinue = result['continue']           \n",
    "        except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Length</th>\n",
       "      <th>Citations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Zweiter Weltkrieg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>355</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Erster Weltkrieg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Kalter Krieg</th>\n",
       "      <td>NaN</td>\n",
       "      <td>39</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Length  Citations\n",
       "Zweiter Weltkrieg    NaN        355\n",
       "Erster Weltkrieg     NaN        364\n",
       "Kalter Krieg         NaN         39"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#GET CITATIONS for EN NET\n",
    "cits_dic = {}\n",
    "\n",
    "for n,i in enumerate(chunks(Articles, 1)):\n",
    "    print('Getting references ',round(100*n/len(Articles),3),'%')\n",
    "    for j in query({'page':'|'.join(i), 'prop':'text'}):\n",
    "        cits = j['text']\n",
    "        for k,v in cits.items():\n",
    "            cits = v\n",
    "            cits = cits.rsplit(\"Edit section: Footnotes\")[0] #rename edit sections according to language\n",
    "            cits = cits.rsplit(\"Edit section: Citations\")[0]\n",
    "            cits = cits.rsplit(\"Edit section: References\")[0]\n",
    "            cits = cits.rsplit(\"Edit section: Bibliography\")[0]\n",
    "            cits = cits.rsplit(\"Edit section: See also\")[0]\n",
    "            cits = reg1.findall(cits)\n",
    "            cits = len(cits)\n",
    "            cits_dic[j['title']] = cits\n",
    "\n",
    "for k,v in cits_dic.items():\n",
    "    cits_dic[k] = v\n",
    "    df['Citations'] = df.index.to_series().map(cits_dic) \n",
    "    \n",
    "#CREATE COLUMN: citations per word\n",
    "df['CitePerWord'] = df['Length'] / df['Citations']\n",
    "display(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#EXPORT DATA\n",
    "os.chdir('path')\n",
    "df.to_csv('%s_Net_Attributes.csv' %lang, encoding='utf_8_sig')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
